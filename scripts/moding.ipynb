{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a473f7-74ba-4cb0-ae73-cecd29a9742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "from typing import List, Union\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "import os\n",
    "import sys\n",
    "import contextlib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def suppress_output():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        old_stderr = sys.stderr\n",
    "        sys.stdout = devnull\n",
    "        sys.stderr = devnull\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "            sys.stderr = old_stderr\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "COLORS = ['#1b9e77', '#d95f02', '#7570b3']  # teal, orange, purple\n",
    "DATA_DIR = '/glade/u/home/kmacmanu/d4-columbia-hurricane-migration/contributors/fcottier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e33a6-441e-4e98-befd-3eb4b4085a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDS=DATA_DIR + os.sep + 'df_migration_hurricane.csv'\n",
    "\n",
    "inputDF=pd.read_csv(inputDS)\n",
    "inputDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b12e1a-f496-4cb1-98cb-53af54449b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDF['pop_2000_ln'] = np.log(inputDF['pop_2000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426b9e5-f6f6-4254-8e3c-4f2ab1e91436",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp=inputDF[['avg_gustW_peak', 'avg_sustW_max',\n",
    "       'max_gustW_peak', 'max_sustW_max', 'pop_2000_ln', 'medIncHH_2000', 'povertyL_2000', 'unempl_2000',\n",
    "       'ownerL_2000', 'afroAmerL_2000', 'rural_L_2000',  'INLECZ']]\n",
    "T = inputDF[['GEOID', 'year',\"nOutMigr_ln\"]]\n",
    "print(f'{Xp.shape=}, {T.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48144f4-a839-4650-ac15-fd1ee5db82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T[\"nOutMigr_ln\"]=T.groupby(\"GEOID\")[\"nOutMigr_ln\"].transform(lambda x:x-x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d968b49-5639-49dc-bab9-af50d77c7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize X\n",
    "Xp = (Xp - Xp.mean(axis=0)) / Xp.std(axis=0)\n",
    "#Xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cdf862-d2f9-4256-b8ad-69f038dd7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp = pd.concat([inputDF[['GEOID', 'year']],Xp],axis=1)\n",
    "Xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a396218d-d72f-4305-b575-0afb06ef3953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(X: np.ndarray, T: np.ndarray) -> Union[List[np.ndarray], List[np.ndarray]]:\n",
    "    #if shuffle\n",
    "    #    rng = np.random.default_rng(seed)\n",
    "    #    indices = rng.permutation(X.shape[0])\n",
    "    #    X, T = X[indices], T[indices]\n",
    "   \n",
    "    #train_end = int(Xp.shape[0] * train_fraction)\n",
    "\n",
    "    # if validation_fraction > 0:\n",
    "    #     valid_end = train_end + int(X.shape[0] * validation_fraction)\n",
    "    #     Xtrain, Xvalid, Xtest = X[:train_end], X[train_end:valid_end], X[valid_end:]\n",
    "    #     Ttrain, Tvalid, Ttest = T[:train_end], T[train_end:valid_end], T[valid_end:]\n",
    "    #     return Xtrain, Ttrain, Xvalid, Tvalid, Xtest, Ttest\n",
    "    # else:\n",
    "    #     Xtrain, Xtest = X[:train_end], X[train_end:]\n",
    "    #     Ttrain, Ttest = T[:train_end], T[train_end:]\n",
    "\n",
    "\n",
    "    Xtrain=X.query('year<2018').drop(['GEOID','year'],axis=1)\n",
    "    Xtest=X.query('year>=2018').drop(['GEOID','year'],axis=1)\n",
    "    Ttrain=T.query('year<2018').drop(['GEOID','year'],axis=1)\n",
    "    Ttest=T.query('year>=2018').drop(['GEOID','year'],axis=1)\n",
    "    idTrain=X.query('year<2018')[['GEOID','year']]\n",
    "    idTest=X.query('year>=2018')[['GEOID','year']]\n",
    "    return Xtrain, Ttrain, Xtest, Ttest, idTrain, idTest\n",
    "   \n",
    "Xtrain, Ttrain, Xtest, Ttest, idTrain, idTest = partition(Xp, T)\n",
    "print(f'{Xtrain.shape=}, {Ttrain.shape=}, {Xtest.shape=}, {Ttest.shape=}, {idTrain.shape=}, {idTest.shape=}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fc_ml]",
   "language": "python",
   "name": "conda-env-fc_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
